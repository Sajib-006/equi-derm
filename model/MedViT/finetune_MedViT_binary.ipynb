{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD9uOPEK65K0",
        "outputId": "dc9c2187-eb1c-4988-946f-925d904a878f"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgm5vmQp8i9h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "from engine import train_one_epoch, evaluate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ta2wQYk78Mg"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEQ5S3_U8E0j"
      },
      "outputs": [],
      "source": [
        "from MedViT import MedViT_small, MedViT_base, MedViT_large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'large' # small, base, large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKcyvB0Y8RsK",
        "outputId": "f8536371-3cd2-4924-e674-af4bf44c980b"
      },
      "outputs": [],
      "source": [
        "if model_name == 'small':\n",
        "    model = MedViT_small()\n",
        "    checkpoint = torch.load('./checkpoints/MedViT_small_im1k.pth')\n",
        "elif model_name == 'base':\n",
        "    model = MedViT_base()\n",
        "    checkpoint = torch.load('./checkpoints/MedViT_base_im1k.pth')\n",
        "elif model_name == 'large':\n",
        "    model = MedViT_large()\n",
        "    checkpoint = torch.load('./checkpoints/MedViT_large_im1k.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the checkpoint into the model\n",
        "model.load_state_dict(checkpoint['model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RE8qlwf8ZV5"
      },
      "outputs": [],
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFXm96Gi8g7u"
      },
      "outputs": [],
      "source": [
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIefIFDW80-U"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChBhSTxK87hc"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH1INOxS8-iM"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 16\n",
        "lr = 0.0005\n",
        "n_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD22o8uW9L1X",
        "outputId": "b47e6cdc-dd42-4b91-8574-db868c638fea"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "from timm.data import create_transform\n",
        "transform = create_transform(\n",
        "            input_size=224,\n",
        "            is_training=True,\n",
        "            color_jitter=0.4,\n",
        "            re_prob=0.25,\n",
        "            re_mode='pixel',\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(root, transform):\n",
        "    from torchvision.datasets.folder import ImageFolder\n",
        "    dataset = ImageFolder(root, transform=transform)\n",
        "    assert len(dataset.class_to_idx) == 2\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_dataset = load_data(root='DDI_data/train', transform=transform)\n",
        "test_dataset = load_data(root='DDI_data/test', transform=transform)\n",
        "val_dataset = load_data(root='DDI_data/val', transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ImKp2m9cLf"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criterion = nn.BCEWithLogitsLoss() # not sure what to use\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, data_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():  # No gradients needed for validation, which saves memory and computations\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets.squeeze().long())\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    \n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampler_train = torch.utils.data.RandomSampler(train_dataset)\n",
        "sampler_test = torch.utils.data.SequentialSampler(test_dataset)\n",
        "sampler_val = torch.utils.data.SequentialSampler(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_loader_train = torch.utils.data.DataLoader(\n",
        "        train_dataset, sampler=sampler_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "data_loader_val = torch.utils.data.DataLoader(\n",
        "    val_dataset, sampler=sampler_val,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    test_dataset, sampler=sampler_val,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    drop_last=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the size of each data set with how many from each class\n",
        "print(f'Train Size: {len(data_loader_train.dataset)}')\n",
        "print(f'Val Size: {len(data_loader_val.dataset)}')\n",
        "print(f'Test Size: {len(data_loader_test.dataset)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = './output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmIo3JWf9lEs",
        "outputId": "822ffbe4-b700-450b-adcc-777a69286208"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize lists to track the losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss = 0\n",
        "    for inputs, targets in tqdm(data_loader_train, desc=f\"Epoch {epoch+1} Training\"):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets.squeeze().long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(data_loader_train)\n",
        "    train_losses.append(avg_train_loss)  # Append average train loss for this epoch\n",
        "\n",
        "    val_loss, val_accuracy = validate(model, data_loader_val)\n",
        "    val_losses.append(val_loss)  # Append validation loss for this epoch\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Train Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRkfM6CM91j8"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCSBTpUy93r-",
        "outputId": "e96ed88d-cab0-4c48-824d-5e210185f803"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, classification_report, accuracy_score\n",
        "\n",
        "\n",
        "def test_model(model, data_loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)[:, 1]  # Get the probability of the positive class\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_probs.extend(probabilities.cpu().numpy())  # Collect probabilities for AUC calculation\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_targets, all_predictions)\n",
        "    f1 = f1_score(all_targets, all_predictions, average='binary')\n",
        "    auc = roc_auc_score(all_targets, all_probs)\n",
        "    report = classification_report(all_targets, all_predictions, target_names=['Class 0', 'Class 1'])\n",
        "\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    print(f'F1 Score: {f1:.2f}')\n",
        "    print(f'AUC ROC Score: {auc:.2f}')\n",
        "    print('Classification Report:')\n",
        "    print(report)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model(model, data_loader_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lets save the model with an appropriate name\n",
        "\n",
        "torch.save(model.state_dict(), f'fine_tuned_binary_MedViT_{model_name}_DDI.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
